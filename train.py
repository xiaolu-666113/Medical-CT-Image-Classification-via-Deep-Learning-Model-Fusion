import torch
import torch.nn as nn
from config import *
from data_loader import get_dataloaders
from models import get_model, FusionModel

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ä½¿ç”¨è®¾å¤‡ï¼š{device}")

train_loader, val_loader = get_dataloaders()
print("ğŸ“¦ æ•°æ®åŠ è½½å®Œæˆï¼")

# åˆå§‹åŒ–å¤šä¸ªåŸºç¡€æ¨¡å‹
base_models = [get_model(name).to(device) for name in model_names]
model = FusionModel(base_models).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=lr)
criterion = nn.CrossEntropyLoss()

def run_epoch(loader, train=True):
    model.train() if train else model.eval()
    total_loss, correct = 0, 0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        if train:
            optimizer.zero_grad()
        with torch.set_grad_enabled(train):
            outputs = model(x)
            loss = criterion(outputs, y)
            if train:
                loss.backward()
                optimizer.step()
        total_loss += loss.item() * x.size(0)
        correct += (outputs.argmax(1) == y).sum().item()
    return total_loss / len(loader.dataset), correct / len(loader.dataset)

best_val_acc = 0
patience = 5
patience_counter = 0
save_path = 'best_model.pth'

for epoch in range(num_epochs):
    train_loss, train_acc = run_epoch(train_loader, train=True)
    val_loss, val_acc = run_epoch(val_loader, train=False)

    print(f"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    # âœ… æ¯è½®æ˜¾ç¤ºèåˆæƒé‡
    norm_weights = model.get_normalized_weights()  # ç¡®ä¿ FusionModel ä¸­æœ‰è¯¥æ–¹æ³•
    print("ğŸ“Š æ¨¡å‹èåˆæƒé‡åˆ†å¸ƒï¼š")
    for name, w in zip(model_names, norm_weights):
        print(f"  {name}: {w:.4f}")

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), save_path)
        print(f"âœ… æ–°æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼Val Acc: {val_acc:.4f}")
        patience_counter = 0
    else:
        patience_counter += 1
        print(f"âš ï¸ éªŒè¯å‡†ç¡®ç‡æœªæå‡ï¼ˆ{patience_counter}/{patience}ï¼‰")

    if patience_counter >= patience:
        print(f"ğŸ›‘ Early stopping è§¦å‘ï¼ŒéªŒè¯å‡†ç¡®ç‡è¿ç»­ {patience} è½®æ— æå‡")
        break
